{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hamblog\n",
    "By Kyle Hambrook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<a href=\"https://khambroo.github.io/hamblog/\">HOME</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Inference for Correlation: Asymptotic Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Statistical Inference Problems for Correlation $\\rho$\n",
    "\n",
    "Let $X$ and $Y$ be random variables. We consider two statistical inference problems for the correlation $\\rho = \\rho(X,Y)$. \n",
    "\n",
    "Problem 1: Test the null hypothesis $H_0$: $\\rho = 0$ by calculating a $p$-value.\n",
    "\n",
    "Problem 2: Determine a confidence interval that contains $\\rho$ with prescribed probability.\n",
    "\n",
    "In this post, we consider asymptotic methods for these problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Asymptotic Distribution of Sample Correlation $r_n$\n",
    "\n",
    "Let $X_1,\\ldots,X_n$ and $Y_1,\\ldots,Y_n$ be random samples of $X$ and $Y$. Let $$r_n = r_n(X_1,\\ldots,X_n,Y_1,\\ldots,Y_n)$$ be the sample correlation.\n",
    "\n",
    "<strong> Theorem 1. </strong>\n",
    "Assume $E(X^4) < \\infty$, $E(Y^4) < \\infty$. Let $(X_i)_{i=1}^{\\infty} \\sim_{iid} X$ and $(Y_i)_{i=1}^{\\infty} \\sim_{iid} Y$ be infinite random samples. Then\n",
    "$$\n",
    "\\sqrt{n}(r_n-\\rho) \\rightarrow_d N_1(0,\\phi^2),\n",
    "$$\n",
    "where $\\phi$ is the positive number defined by \n",
    "$$\n",
    "\\phi^2 = \\frac{1}{4}\\rho^2( E(X_{\\ast}^4) + E(Y_{\\ast}^4) + 2E(X_{\\ast}^2 Y_{\\ast}^2) ) \n",
    "- \\rho(  E(X_{\\ast}^3 Y_{\\ast}) +  E(X_{\\ast} Y_{\\ast}^3)  )   +   E(X_{\\ast}^2 Y_{\\ast}^2),\n",
    "$$\n",
    "with $X_{\\ast} = (X - E (X))/\\sqrt{\\text{Var} (X)}$ and $Y_{\\ast} = (Y - E (Y))/\\sqrt{\\text{Var} (Y)}$.\n",
    "\n",
    "<strong> Remark. </strong> In general, the variance of the limiting distribution depends on higher moments of $(X,Y)$. However, if $\\rho = 0$, the variance of the limiting distribution is \n",
    "$$\n",
    "\\phi^2 = E(X_{\\ast}^2 Y_{\\ast}^2) \n",
    "= E(X_{\\ast}^2) E(Y_{\\ast}^2) \n",
    "= \\frac{\\text{Var}(X)}{\\text{Var}(X)} \\cdot \\frac{\\text{Var}(Y)}{\\text{Var}(Y)}\n",
    "=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Hypothesis Test Based on Sample Correlation $r_n$\n",
    "\n",
    "Let $r_n'$ denote an observed value (or realization) of $r_n$. Precisely, $$r_n' = r_n(X_1(\\omega'),\\ldots, X_n(\\omega'),Y_1(\\omega'),\\ldots,Y_n(\\omega'))$$ for some fixed outcome $\\omega'$ in the sample space.\n",
    "\n",
    "$H_0$ stands for the statement $\\rho = 0$. It is called the null hypothesis. \n",
    "\n",
    "Informally, the $p$-value is the probability of $r_n$ being at least as extreme as the observed value $r_n'$ assuming $H_0$ is true. What \"extreme\" means depends on the distribution of $r_n$. We give a precise defintion of the $p$-value below, but first we discuss its meaning.\n",
    "\n",
    "A small $p$-value is often interpreted as evidence against the null hypothesis $H_0$. However, let us emphasize what the $p$-value is not. It is __not__ the probability that $H_0$ is true. It is __not__ the probability of $H_0$ given the observed data. <!--It is __not__ the probability of $r_n$ being equal to the observed value assuming that $H_0$ is true.-->\n",
    "\n",
    "The following figure (borrowed from wikipedia) helps illustrate the concept of $p$-value.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/3a/P-value_in_statistical_significance_testing.svg\" alt=\"alt text\" style=\"width: 400px;\" title=\"Logo Title Text 1\">\n",
    "\n",
    "To compute the $p$-value, we need the distribution of $r_n$. We use the asymptotic approximation suggested by Theorem 1: $$r_n \\sim N(0,n) \\text{ given } H_0.$$\n",
    "\n",
    "If $r_n' > 0$, the one-sided $p$-value is\n",
    "$$\n",
    "P(r_n \\geq r_n' \\; | \\;  H_0).\n",
    "$$\n",
    "It is the area of the right-tail region under the standard normal pdf to the right of $\\sqrt{n} r_n'$ (assuming the asymptotic approximation for the distribution of $r_n$). \n",
    "\n",
    "If $r_n' < 0$, the one-sided $p$-value is\n",
    "$$\n",
    "P(r_n \\leq r_n' \\; | \\;  H_0)\n",
    "$$\n",
    "It is the area of the left-tail region under the standard normal pdf to the left of $\\sqrt{n} r_n'$ (assuming the asymptotic approximation for the distribution of $r_n$). \n",
    "\n",
    "The two-sided $p$-value is\n",
    "$$\n",
    "P(r_n \\leq -|r_n'| \\text{ or } r_n \\geq |r_n'|  \\; | \\;  H_0).\n",
    "$$ \n",
    "It is the area of the left-tail region under the standard normal pdf to the left of $-\\sqrt{n}|r_n'|$ plus the area of the right-tail region to the right of $\\sqrt{n}|r_n'|$ (assuming the asymptotic approximation for the distribution of $r_n$). \n",
    "\n",
    "For simplicity, let's focus on the one-sided $p$-value when $r_n' < 0$. For brevity, denote the $p$-value by\n",
    "$$\n",
    "p_n = P(r_n \\leq r_n' \\; | \\;  H_0).\n",
    "$$\n",
    "\n",
    "By Theorem 1, we know\n",
    "$$\n",
    "\\lim_{n \\to \\infty} p_n = \\Phi(\\sqrt{n} r_n').\n",
    "$$\n",
    "where $\\Phi$ is the standard normal cdf. The asymptotic approximation is\n",
    "$$\n",
    "p_n = \\Phi(\\sqrt{n} r_n').\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Python Example 1\n",
    "\n",
    "In Python Example 1, we will test the asymptotic approximation by repeated sampling. Here are the steps:\n",
    "\n",
    "1. Choose a distribution for $(X,Y)$ with $\\rho(X,Y) = 0$ ($H_0$ true). We'll use a multi-variate normal distribution.\n",
    "2. Choose a value of $n$.  \n",
    "3. Set $\\sqrt{n}r_n' = -2$.\n",
    "4. Draw a size-$n$ sample of $(X,Y)$ and compute $r_n$. This is $r_n'$ \n",
    "5. Repeat step 4 many times. Say $N$ times in total.\n",
    "5. Record $K$ = number of times where $r_n \\leq r_n'$. \n",
    "6. Treat $K/N$ as $p_n = P(r_n \\leq r_n' \\; | \\;  H_0)$. By the law of large numbers, $K/N$ converges to $p_n$ as $N$ gets large.\n",
    "7. Repeat steps 2 to 6 several times.\n",
    "8. Plot $p_n$ vs $n$. Also draw the horizontal line for $\\Phi(\\sqrt{n}r_n') = \\Phi(-1.96) \\approx 0.025$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0203842418617\n",
      "-0.0517883164198\n",
      "0.0322923602695\n",
      "-0.0301055265407\n",
      "0.00263167014826\n",
      "0.00519913920782\n",
      "0.00286682259571\n",
      "0.0474199267189\n",
      "0.00737813664163\n",
      "0.00600183156893\n",
      "0.00397289237865\n",
      "-0.000165038457207\n",
      "0.000231697737555\n",
      "-0.0027234337985\n",
      "-0.00266465878462\n",
      "0.00103627828635\n",
      "-0.00125494911651\n",
      "0.00341193825774\n",
      "0.00130542463337\n",
      "0.0023547530068\n",
      "(X,Y) multivariate normal, true correlation rho(X,Y) =  0\n",
      "plot p-value p_n vs sample size n\n",
      "horizontal line is Phi(sqrt(n)r'_n) = \\Phi(-1.96) =  0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAETCAYAAAAoF0GbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMhSSpJahkCS1DIUkqfV/D9f+/dX8FqoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9c37438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "def samp_corr( X,Y ):\n",
    "    #X,Y vectors length n\n",
    "    mean_X = np.mean(X)\n",
    "    mean_Y = np.mean(Y)\n",
    "    numerator = np.mean((X-mean_X)*(Y-mean_Y))\n",
    "    denominator = np.sqrt(np.mean((X-mean_X)**2) * np.mean((Y-mean_Y)**2))\n",
    "    return numerator/denominator;\n",
    "\n",
    "rho = 0\n",
    "cov = np.array( [[1,rho],[rho,1]] )\n",
    "\n",
    "pn = []\n",
    "samplesizes = [10**2,10**3,10**4,10**5,10**6,5*10**2,5*10**3,5*10**4,5*10**5,5*10**6]\n",
    "samplesizes = [10**3,10**5]\n",
    "for n in samplesizes: \n",
    "    rn_prime = 0/np.sqrt(n)\n",
    "    N = 10\n",
    "    K=0\n",
    "    for j in xrange(1,N+1):\n",
    "        XY = np.random.multivariate_normal([0,0],cov,n)\n",
    "        X = XY[:,0]\n",
    "        Y = XY[:,1]\n",
    "        rn = samp_corr(X,Y)\n",
    "        print rn\n",
    "        if rn <= rn_prime:\n",
    "            K=K+1\n",
    "    pn.append(K/N)\n",
    "Phi = norm.cdf(-0)\n",
    "\n",
    "print \"(X,Y) multivariate normal, true correlation rho(X,Y) = \",rho\n",
    "print \"plot p-value p_n vs sample size n\"\n",
    "print \"horizontal line is Phi(sqrt(n)r'_n) = \\Phi(-1.96) = \", Phi\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "plt.plot(samplesizes,pn,\"o\")\n",
    "plt.axhline(Phi)\n",
    "plt.ylim([0,1])\n",
    "ax.set_xlabel(r'$n$')\n",
    "ax.set_ylabel(r'$p_n$')\n",
    "ax.set_xscale('log')  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. Python Example 2\n",
    "\n",
    "In Python Example 2, we will test the asymptotic approximation another way. To explain the test, first we need some theory.\n",
    "\n",
    "Remember that a random variable is just a (measurable) function from the sample space to the real numbers. The $p$-value $p_n$ can be viewed as a random variable.  To each outcome $\\omega'$ in the sample space, assign the real number\n",
    "$$\n",
    "p_n(\\omega') = P(r_n \\leq r_n' \\; | \\;  H_0)\n",
    "$$\n",
    "where $r_n' = r_n(X_1(\\omega'),\\ldots, X_n(\\omega'),Y_1(\\omega'),\\ldots,Y_n(\\omega'))$.\n",
    "\n",
    "<strong>Theorem 2. </strong>\n",
    "The $p$-value $p_n$ is uniformly distributed on $[0,1]$: $P(p_n \\leq \\alpha) = \\alpha$ for all $\\alpha \\in [0,1]$.\n",
    "\n",
    "Now fix $\\alpha \\in (0,1)$. If $p_n \\leq \\alpha$ and the null hypothesis $H_0$ is true, we say we have a Type 1 error at significance level $\\alpha$. Remember that the statement $p_n \\leq \\alpha$ is viewed as stronger evidence against the null hypothesis when $\\alpha$ is smaller. So a Type 1 error is \"$p$-value says $H_0$ false but $H_0$ is true.\" \n",
    "\n",
    "According to Theorem 2, the probability of a Type 1 error at signifiance level $\\alpha$ is \n",
    "$$P(p_n \\leq \\alpha) = \\alpha.$$ \n",
    "<!--We want to compare $P(p_n \\leq \\alpha) = \\alpha$ to $P(\\Phi(\\sqrt{n} r_n') \\leq \\alpha)$-->\n",
    "We want to compare $P(\\Phi(\\sqrt{n} r_n') \\leq \\alpha)$ to $\\alpha$. Here's how will we do it:\n",
    "\n",
    "1. Choose a distribution for $(X,Y)$ with $\\rho(X,Y) = 0$ ($H_0$ true).\n",
    "2. Choose $\\alpha \\in (0,1)$. \n",
    "3. Choose a value of $n$.\n",
    "4. Sample from $(X,Y)$ and compute $\\Phi( \\sqrt{n} r_n')$\n",
    "5. Repeat Step 4 $N$ times. Record $K$ = number of times $\\Phi( \\sqrt{n} r_n') \\leq \\alpha$.\n",
    "6. Treat $K / N$ as $P(\\Phi( \\sqrt{n} r_n') \\leq \\alpha)$. By the law of large numbers, $K/N$ converges to $P(\\Phi( \\sqrt{n} r_n') \\leq \\alpha)$ as $N$ gets large.\n",
    "7. Compute the error $|\\alpha - P(\\Phi(\\sqrt{n} r_n') \\leq \\alpha)|$\n",
    "8. Repeat 3-7 for many values of $n$. Plot the error vs n\n",
    "9. Repeat 2 to 8 for many values of $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "def samp_corr( X,Y ):\n",
    "    #X,Y vectors length n\n",
    "    mean_X = np.mean(X)\n",
    "    mean_Y = np.mean(Y)\n",
    "    numerator = np.mean((X-mean_X)*(Y-mean_Y))\n",
    "    denominator = np.sqrt(np.mean((X-mean_X)**2) * np.mean((Y-mean_Y)**2))\n",
    "    return numerator/denominator;\n",
    "\n",
    "rho = 0\n",
    "cov = np.array( [[1,rho],[rho,1]] )\n",
    "\n",
    "\n",
    "#alphavalues = [0.01,0.05,0.1]\n",
    "alpha = 0.05\n",
    "samplesizes = [10**3,10**4,10**5,10**6]\n",
    "vec_avg_error_n = []\n",
    "for n in samplesizes: \n",
    "    vec_error = []\n",
    "    \n",
    "    \n",
    "print \"(X,Y) multivariate normal, true correlation rho(X,Y) = \",rho\n",
    "print \"plot E(r_n(X,Y)) = expected sample correlation vs n = sample size\"\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "plt.plot(samplesizes,E_r_n,\"o\")\n",
    "plt.axhline(alpha)\n",
    "plt.ylim([0.42,0.58])\n",
    "ax.set_xlabel(r'$n$')\n",
    "ax.set_ylabel(r'$E(r_n(X,Y))$')\n",
    "ax.set_xscale('log') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Confidence Interval Based on Sample Correlation\n",
    "\n",
    "Confidence interval. Issue because of $\\phi$. Estimate it.\n",
    "\n",
    "Let $\\theta \\in \\mathbb{R}$ be a parameter for the distribution of $X$. \n",
    "<!--Suppose $T$ is an estimator of $\\theta$.-->\n",
    "Let $I(T)$ be an interval whose endpoints are functions of $T$. \n",
    "\n",
    "$I(T)$ is called a $95\\%$ confidence interval for $\\theta$ based on $T$ if $P(\\theta \\in I(T)) \\geq 0.95$. For $\\alpha \\in (0,1)$, $I(T)$ is called a $(1-\\alpha)\\%$ confidence interval for $\\theta$ based on $T$ if $P(\\theta \\in I(T)) \\geq 1-\\alpha$. \n",
    "\n",
    "Obviously, $\\mathbb{R}$ is a $(1-\\alpha)100\\%$ confidence interval for every $\\alpha \\in (0,1)$. We usually want the smallest $(1-\\alpha)100\\%$ confidence interval possible. We also often want the confidence interval to be centered at $T$.\n",
    "\n",
    "__Remark.__ The hypothesis test for $\\rho = \\rho_0$, where $\\rho_0$ is a fixed non-zero number, has the same issue.\n",
    "\n",
    "Another solution is in the next post. Fisher transformation.\n",
    "\n",
    "Unfortunately, the $\\phi$ on the right-hand side means we can't compute this approximation. To overcome this, we will estimate \n",
    "$$\n",
    "\\phi^2 = E(X_{\\ast}^2 Y_{\\ast}^2) = E\n",
    "$$\n",
    "by \n",
    "$$\n",
    "\\widehat{\\phi^2} = \\frac{1}{n} \\sum_{i=1}^{n} \n",
    "$$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a href=\"https://khambroo.github.io/hamblog/\">HOME</a> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
